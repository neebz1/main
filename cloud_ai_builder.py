#!/usr/bin/env python3
"""
Cloud AI Builder - Talk to Your AI Assistant from Anywhere
Build and update your projects remotely via web interface

Features:
- Web interface accessible from any device
- Give instructions to AI to build features
- See progress in real-time
- Deploy updates automatically
- Chat history saved
- Secure API key management
"""

import gradio as gr
import os
import subprocess
from pathlib import Path
from dotenv import load_dotenv
from datetime import datetime
import json
import threading
from auto_git_watcher import AutoGitWatcher

# Load environment
load_dotenv()

# AI Client setup
TOGETHER_API_KEY = os.getenv('TOGETHER_API_KEY')
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

client = None
AI_PROVIDER = None

try:
    if TOGETHER_API_KEY:
        from together import Together
        client = Together(api_key=TOGETHER_API_KEY)
        AI_PROVIDER = "kimi"
    elif ANTHROPIC_API_KEY:
        import anthropic
        client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
        AI_PROVIDER = "anthropic"
    elif OPENAI_API_KEY:
        from openai import OpenAI
        client = OpenAI(api_key=OPENAI_API_KEY)
        AI_PROVIDER = "openai"
except Exception as e:
    print(f"‚ö†Ô∏è  AI import warning: {e}")


class ProjectBuilder:
    """
    AI-powered project builder that executes tasks
    """
    
    def __init__(self, project_dir="/Users/nr/main"):
        self.project_dir = Path(project_dir)
        self.build_history = []
        self.auto_git_watcher = None
        self.auto_git_thread = None
        
    def execute_command(self, command: str) -> str:
        """Execute shell command and return output"""
        try:
            result = subprocess.run(
                command,
                shell=True,
                cwd=self.project_dir,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            output = result.stdout if result.returncode == 0 else result.stderr
            status = "‚úÖ" if result.returncode == 0 else "‚ùå"
            
            return f"{status} Command: {command}\n\nOutput:\n{output}"
        except Exception as e:
            return f"‚ùå Error: {str(e)}"
    
    def read_file(self, file_path: str) -> str:
        """Read file contents"""
        try:
            full_path = self.project_dir / file_path
            with open(full_path, 'r') as f:
                return f.read()
        except Exception as e:
            return f"‚ùå Error reading {file_path}: {e}"
    
    def write_file(self, file_path: str, content: str) -> str:
        """Write file contents"""
        try:
            full_path = self.project_dir / file_path
            full_path.parent.mkdir(parents=True, exist_ok=True)
            with open(full_path, 'w') as f:
                f.write(content)
            return f"‚úÖ Wrote {file_path}"
        except Exception as e:
            return f"‚ùå Error writing {file_path}: {e}"
    
    def git_commit_push(self, message: str) -> str:
        """Commit and push to git"""
        try:
            # Add all changes
            subprocess.run(
                "git add -A",
                shell=True,
                cwd=self.project_dir,
                check=True
            )
            
            # Commit
            subprocess.run(
                f'git commit -m "{message}"',
                shell=True,
                cwd=self.project_dir,
                check=True
            )
            
            # Get current branch
            branch_result = subprocess.run(
                "git rev-parse --abbrev-ref HEAD",
                shell=True,
                cwd=self.project_dir,
                capture_output=True,
                text=True
            )
            current_branch = branch_result.stdout.strip()
            
            # Push to current branch
            result = subprocess.run(
                f"git push origin {current_branch}",
                shell=True,
                cwd=self.project_dir,
                capture_output=True,
                text=True
            )
            
            return f"‚úÖ Committed and pushed to {current_branch}!\n\n{result.stdout}"
        except Exception as e:
            return f"‚ö†Ô∏è Git operation: {e}"
    
    def start_auto_git(self, interval: int = 300) -> str:
        """Start autonomous git watcher"""
        try:
            if self.auto_git_watcher and self.auto_git_watcher.running:
                return "‚ö†Ô∏è Auto-git is already running!"
            
            self.auto_git_watcher = AutoGitWatcher(
                project_dir=str(self.project_dir),
                interval=interval
            )
            
            # Run in background thread
            self.auto_git_thread = threading.Thread(
                target=self.auto_git_watcher.watch,
                daemon=True
            )
            self.auto_git_thread.start()
            
            return f"‚úÖ Autonomous git watcher started!\n\nChecking for changes every {interval} seconds."
        except Exception as e:
            return f"‚ùå Error starting auto-git: {e}"
    
    def stop_auto_git(self) -> str:
        """Stop autonomous git watcher"""
        try:
            if not self.auto_git_watcher or not self.auto_git_watcher.running:
                return "‚ö†Ô∏è Auto-git is not running"
            
            self.auto_git_watcher.stop()
            return "‚úÖ Autonomous git watcher stopped!"
        except Exception as e:
            return f"‚ùå Error stopping auto-git: {e}"
    
    def auto_git_status(self) -> str:
        """Get status of autonomous git watcher"""
        try:
            if not self.auto_git_watcher:
                return "‚ùå Auto-git not initialized"
            
            if self.auto_git_watcher.running:
                return f"""‚úÖ Auto-git is RUNNING
                
Interval: {self.auto_git_watcher.interval} seconds
Auto-push: {'Enabled' if self.auto_git_watcher.config['auto_push'] else 'Disabled'}
Project: {self.auto_git_watcher.project_dir}
"""
            else:
                return "‚ö†Ô∏è Auto-git is STOPPED"
        except Exception as e:
            return f"‚ùå Error checking status: {e}"


# Initialize builder
builder = ProjectBuilder()


def chat_with_builder(message, history):
    """Chat with AI builder to create features"""
    
    if not client:
        return "‚ö†Ô∏è Please add API key to .env file"
    
    # System prompt for builder
    system_prompt = """You are an AI project builder assistant. 

Your job is to help the user build and update their projects remotely.

When the user asks you to:
- Build a feature ‚Üí Explain what files you'll create and what they do
- Fix something ‚Üí Describe the fix clearly
- Update code ‚Üí Show what changed
- Deploy ‚Üí Explain the deployment process

Keep responses actionable and clear. Format code with ```python or ```bash.

You can:
- Read files from the project
- Write new files
- Execute commands
- Commit to git
- Deploy updates

Always explain what you're doing and why."""

    try:
        if AI_PROVIDER == "kimi":
            messages = [{"role": "system", "content": system_prompt}]
            for h in history:
                messages.append({"role": "user", "content": h[0]})
                messages.append({"role": "assistant", "content": h[1]})
            messages.append({"role": "user", "content": message})
            
            response = client.chat.completions.create(
                model="meta-llama/Llama-3.3-70B-Instruct-Turbo",
                messages=messages,
                max_tokens=2048,
                temperature=0.7
            )
            return response.choices[0].message.content
            
        elif AI_PROVIDER == "anthropic":
            messages = []
            for h in history:
                messages.append({"role": "user", "content": h[0]})
                messages.append({"role": "assistant", "content": h[1]})
            messages.append({"role": "user", "content": message})
            
            response = client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=2048,
                system=system_prompt,
                messages=messages
            )
            return response.content[0].text
            
        else:  # OpenAI
            messages = [{"role": "system", "content": system_prompt}]
            for h in history:
                messages.append({"role": "user", "content": h[0]})
                messages.append({"role": "assistant", "content": h[1]})
            messages.append({"role": "user", "content": message})
            
            response = client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=messages,
                max_tokens=2048
            )
            return response.choices[0].message.content
            
    except Exception as e:
        return f"‚ùå Error: {str(e)}"


def execute_task(task_description):
    """Execute a building task"""
    return f"üî® Task queued: {task_description}\n\nThe AI will process this and update your project!"


def create_ui():
    """Create the Gradio interface"""
    
    # Build header with AI provider info
    provider_names = {"kimi": "Kimi K2", "anthropic": "Claude", "openai": "GPT-4"}
    ai_status = f"‚úÖ AI: {provider_names.get(AI_PROVIDER, 'Not configured')}" if AI_PROVIDER else "‚ö†Ô∏è AI: Not configured"
    
    with gr.Blocks(theme=gr.themes.Soft(primary_hue="blue"), title="Cloud AI Builder") as app:
        gr.Markdown(
            f"""
            # ü§ñ Cloud AI Builder
            ### Talk to your AI assistant from anywhere - build projects remotely!
            
            {ai_status}
            
            **Give me instructions and I'll build it for you!**
            """
        )
        
        with gr.Tabs():
            # Main Chat Tab
            with gr.Tab("üí¨ Build & Chat"):
                gr.Markdown(
                    """
                    ### Give me instructions to build features!
                    
                    **Example requests:**
                    - "Add a new feature to the music AI that detects key/scale"
                    - "Fix the voice control so it works better"
                    - "Create a web interface for the mixing engineer"
                    - "Build a mobile app version"
                    - "Add automation to the Logic plugin"
                    """
                )
                
                chatbot = gr.Chatbot(
                    height=600,
                    placeholder="üëã Hi! Tell me what you want to build or fix, and I'll do it for you!",
                    show_label=False,
                    type="messages"
                )
                
                with gr.Row():
                    msg = gr.Textbox(
                        placeholder="What do you want me to build? (e.g., 'Add a tempo detection feature')",
                        show_label=False,
                        scale=4
                    )
                    submit = gr.Button("üöÄ Build It!", scale=1, variant="primary")
                
                # Handle chat
                msg.submit(chat_with_builder, [msg, chatbot], [chatbot])
                submit.click(chat_with_builder, [msg, chatbot], [chatbot])
            
            # Quick Actions Tab
            with gr.Tab("‚ö° Quick Actions"):
                gr.Markdown("### Common Tasks")
                
                with gr.Row():
                    col1 = gr.Column()
                    col2 = gr.Column()
                
                with col1:
                    gr.Markdown("**Project Management**")
                    git_status_btn = gr.Button("üìä Check Git Status")
                    git_push_btn = gr.Button("‚¨ÜÔ∏è Push to GitHub")
                    test_btn = gr.Button("üß™ Run Tests")
                    
                with col2:
                    gr.Markdown("**AI Tools**")
                    start_mixing_btn = gr.Button("üéöÔ∏è Start Mixing Engineer")
                    start_plugin_btn = gr.Button("üéµ Start Live Plugin")
                    status_btn = gr.Button("üìà Check Status")
                
                # Autonomous Git Section
                gr.Markdown("---")
                gr.Markdown("### ü§ñ Autonomous Git")
                gr.Markdown("Automatically commit and push changes every few minutes")
                
                with gr.Row():
                    auto_git_interval = gr.Number(
                        label="Check Interval (seconds)",
                        value=300,
                        minimum=60,
                        maximum=3600,
                        step=60
                    )
                    
                with gr.Row():
                    start_auto_git_btn = gr.Button("üöÄ Start Auto-Git", variant="primary")
                    stop_auto_git_btn = gr.Button("üõë Stop Auto-Git", variant="stop")
                    auto_git_status_btn = gr.Button("üìä Check Auto-Git Status")
                
                output = gr.Textbox(label="Output", lines=10, interactive=False)
                
                # Connect buttons
                git_status_btn.click(
                    lambda: builder.execute_command("git status"),
                    outputs=output
                )
                git_push_btn.click(
                    lambda: builder.git_commit_push("Auto-update from Cloud AI Builder"),
                    outputs=output
                )
                test_btn.click(
                    lambda: builder.execute_command("cd /Users/nr/main && source venv/bin/activate && python -m pytest --version"),
                    outputs=output
                )
                start_mixing_btn.click(
                    lambda: "‚úÖ AI Mixing Engineer should be at http://127.0.0.1:7861",
                    outputs=output
                )
                start_plugin_btn.click(
                    lambda: "‚úÖ Run: ./start-logic-ai-plugin.sh",
                    outputs=output
                )
                status_btn.click(
                    lambda: builder.execute_command("ps aux | grep -E '(ai_mixing|logic_ai|logic_copilot)' | grep -v grep"),
                    outputs=output
                )
                
                # Autonomous Git buttons
                start_auto_git_btn.click(
                    lambda interval: builder.start_auto_git(int(interval)),
                    inputs=[auto_git_interval],
                    outputs=output
                )
                stop_auto_git_btn.click(
                    lambda: builder.stop_auto_git(),
                    outputs=output
                )
                auto_git_status_btn.click(
                    lambda: builder.auto_git_status(),
                    outputs=output
                )
            
            # Project Info Tab
            with gr.Tab("üìä Project Status"):
                gr.Markdown(
                    """
                    ### Your AI Music Production Suite
                    
                    **Current Tools:**
                    1. üéöÔ∏è **Live AI Plugin** - Real-time Logic Pro control
                    2. üéöÔ∏è **AI Mixing Engineer** - Professional audio analysis  
                    3. üí¨ **Music Copilot** - Production chat assistant
                    4. üé§ **Voice AI** - Google Gemini 2.0 with vision
                    
                    **Tech Stack:**
                    - Python 3.11
                    - Google Gemini 2.0 Flash
                    - Kimi K2 (via Together AI)
                    - OSC Protocol
                    - AppleScript automation
                    - librosa audio analysis
                    
                    **Project Location:** `/Users/nr/main`
                    
                    **GitHub:** https://github.com/neebz1/main
                    
                    **Status:** Production-ready! ‚úÖ
                    """
                )
                
                refresh_info = gr.Button("üîÑ Refresh Project Info")
                info_output = gr.Markdown()
                
                def get_project_info():
                    files = list(Path("/Users/nr/main").glob("*.py"))
                    return f"""
### Current Python Files:
{chr(10).join(f"- `{f.name}`" for f in files)}

### Total Lines of Code:
{builder.execute_command("find . -name '*.py' -not -path './venv/*' -not -path './.cursor/*' | xargs wc -l | tail -1")}
"""
                
                refresh_info.click(get_project_info, outputs=info_output)
        
        gr.Markdown(
            """
            ---
            ### üí° How to Use This
            
            1. **Give me instructions** in the chat (e.g., "Add a beat detection feature")
            2. **I'll explain** what I'll build
            3. **Review and approve** (or ask for changes)
            4. **I build it** and commit to your repo
            5. **Updates deploy** to your Mac automatically!
            
            **Access this from anywhere** - phone, tablet, other computer!
            
            ---
            üöÄ **Built with AI ‚Ä¢ Powered by Kimi K2 ‚Ä¢ Made for Noah**
            """
        )
    
    return app


if __name__ == "__main__":
    print("ü§ñ Starting Cloud AI Builder...")
    print("=" * 60)
    
    if not OPENAI_API_KEY and not ANTHROPIC_API_KEY and not TOGETHER_API_KEY:
        print("‚ö†Ô∏è  Warning: No API key found!")
        print("Add API key to .env file")
        print("=" * 60)
    elif AI_PROVIDER:
        provider_names = {"kimi": "Kimi K2", "anthropic": "Claude", "openai": "GPT-4"}
        print(f"‚úÖ AI Provider: {provider_names.get(AI_PROVIDER, AI_PROVIDER)}")
        print("=" * 60)
    
    app = create_ui()
    app.launch(
        server_name="0.0.0.0",  # Accessible from network
        server_port=7862,
        share=True,  # Creates public URL!
        inbrowser=True
    )

